{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#O istraživanju\n"
      ],
      "metadata": {
        "id": "Af68Xef2PjOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rad spada u primjenjeno istraživanje prema svrsi s obzirom da je algoritam u radu nastao\n",
        "kao poboljšanje algoritma koji se često koristi u praksi. U samom radu se kroz mjeru pogreške\n",
        "pokazuje poboljšanje algoritma nad 10 klasičnih problema strojnog učenja.\n",
        "<br><br>\n",
        "Prema dubini rad je teško svrstati s obzirom da je njegova svrha preinaka nad već postojećim algoritmom no u radu se uspoređuju utjecaji raznih algoritama na uspješnost rješavanja problema stoga bi ga svrstali pod korelacijsko istraživanje.\n",
        "<br><br>\n",
        "U istaživanju možemo primjetit da se osim numeričkih podataka koriste i opisni podaci, ali se oboje obrađuju metodama strojnog učenja te je zato istraživanje kvantitativno.\n",
        "<br><br>\n",
        "Određeni parametri modela se namještaju ovisno o modelu i podacima s kojima se radi stoga istraživanje možemo smatrati kvazi-eksperimentalnim.\n",
        "<br><br>\n",
        "Kroz istraživanje dolazi se do zaključka uspješnosti poboljšanja algoritma preko\n",
        "analize vrijednosti pogrešaka što ukazuje na deduktivno istraživanje koje obično vežemo sa kvantitativnim istraživanjima.\n",
        "<br><br>\n",
        "Samo istraživanje nije vezano vremenski na proučavanje problema\n",
        "stoga spada u sinkrono istraživanje.\n",
        "<br><br>\n",
        "Podaci su uzeti od skupova podataka koji su već objavljeni na internetu te sami istraživači nisu provodili prikupljanje podataka zato je prema izvoru\n",
        "informacija ovo sekundarno istraživanje.\n",
        "<br><br>\n",
        "Iz istog razloga kao u prethodnom paragrafu zaključujemo da je riječ\n",
        "o dokumentarnom istraživanju.\n",
        "<br><br>\n",
        "Metode kako su skupovi podataka prikupljeni su nepoznate s obzirom da se koriste klasični skupovi podataka s interneta koji na stranicama obično nude samo skupove podataka, a i ne način na koji su prikupljeni.\n",
        "<br><br>\n",
        "S obzirom da su stranice na kojima se nalaze spomenuti skupovi podataka\n",
        "namijenjene skupljanjem podataka očekivano je da se prate uvjeti stranice\n",
        "koji bi trebali biti u skladu s pravilima istraživačke etike.\n"
      ],
      "metadata": {
        "id": "dp2UPJFZPura"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo4DXhbt5hPM"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCnIWplxF-Sh"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree._tree import TREE_LEAF\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "class CustomModel:\n",
        "  def __init__(self, rfc, svclass,flag = False):\n",
        "    self.rfc = rfc\n",
        "    self.SVClass = svclass\n",
        "    self.trees_cont = []\n",
        "    self.glob_pairs = {}\n",
        "    self.flag = flag\n",
        "\n",
        "  def train(self,X_train,y_train):\n",
        "    self.rfc.fit(X_train,y_train)\n",
        "    self.setTreesCont()\n",
        "    X_svc_train = self.get_ind_vectors(X_train)\n",
        "    self.SVClass.fit(X_svc_train,y_train)\n",
        "    return\n",
        "\n",
        "  def predict(self,x_test):\n",
        "    fi = self.get_ind_vectors(x_test)\n",
        "    return self.SVClass.predict(fi)\n",
        "\n",
        "  def get_norms(self):\n",
        "    W = self.SVClass.coef_\n",
        "    W = np.square(W)\n",
        "\n",
        "    if not self.flag:\n",
        "      W = np.sum(W,axis = 0)\n",
        "    \n",
        "    return np.sqrt(W)\n",
        "  \n",
        "  \n",
        "\n",
        "  def conn_leaf_values(self):\n",
        "    shift = 0\n",
        "    W = self.get_norms()\n",
        "    self.glob_pairs = {}\n",
        "\n",
        "    for tree_id,tree in enumerate(self.rfc.estimators_):      \n",
        "      paired = []\n",
        "      leaves_order = self.trees_cont[tree_id]\n",
        "\n",
        "      for i in range(tree.tree_.node_count):\n",
        "\n",
        "        left_child = tree.tree_.children_left[i]\n",
        "        right_child = tree.tree_.children_right[i]\n",
        "\n",
        "        if (left_child != TREE_LEAF \n",
        "           and right_child != TREE_LEAF \n",
        "           and left_child in leaves_order \n",
        "           and right_child in leaves_order):\n",
        "          \n",
        "          s1 = leaves_order.index(left_child)\n",
        "          s2 = leaves_order.index(right_child)\n",
        "          \n",
        "          self.glob_pairs[(i,tree_id)] = W[shift+s1]+W[shift+s2]\n",
        "\n",
        "      shift += len(leaves_order) \n",
        "\n",
        "    return\n",
        "\n",
        "  def find_minimum(self):\n",
        "\n",
        "    for i in range(round(len(self.glob_pairs)*0.05)):  \n",
        "      key = min(self.glob_pairs,key = self.glob_pairs.get)\n",
        "      tree = self.rfc.estimators_[key[1]].tree_\n",
        "\n",
        "      self.trees_cont[key[1]].remove(tree.children_left[key[0]])\n",
        "      self.trees_cont[key[1]].remove(tree.children_right[key[0]])\n",
        "      self.trees_cont[key[1]].append(key[0])\n",
        "\n",
        "      tree.children_left[key[0]] = TREE_LEAF\n",
        "      tree.children_right[key[0]] = TREE_LEAF\n",
        "      \n",
        "      self.glob_pairs.pop(key)\n",
        "      \n",
        "    return\n",
        "\n",
        "  def pruning_iter(self,x_train,y_train):\n",
        "    self.conn_leaf_values()\n",
        "    self.find_minimum()\n",
        "    self.SVClass.fit(self.get_ind_vectors(x_train),y_train)\n",
        "    return\n",
        "  \n",
        "  \n",
        "\n",
        "  def setTreesCont(self):\n",
        "    self.trees_cont = list()\n",
        "    for tree in self.rfc.estimators_:\n",
        "      tree_ = tree.tree_\n",
        "      leaf_nodes = [x for x in range(tree_.node_count) if tree_.children_left[x] == TREE_LEAF and tree_.children_right[x] == TREE_LEAF]\n",
        "      self.trees_cont.append(leaf_nodes)\n",
        "    return\n",
        "\n",
        "  def get_n_leaves(self):\n",
        "      return sum(len(cont) for cont in self.trees_cont)\n",
        "\n",
        "  def get_ind_vectors(self,x_train):\n",
        "    X_N = x_train.shape[0]\n",
        "    dim2 = self.get_n_leaves()\n",
        "    \n",
        "    forest_MAT = np.zeros((X_N,dim2))\n",
        "    shift = 0\n",
        "\n",
        "    for id,tree in enumerate(self.rfc.estimators_):\n",
        "      tree_ = tree.tree_\n",
        "      leaf_glob_idx = tree.apply(x_train)\n",
        "      leaves_order = self.trees_cont[id]\n",
        "\n",
        "      leaf_only_idx = [leaves_order.index(x) for x in leaf_glob_idx]\n",
        "\n",
        "      for cnt,idx in enumerate(leaf_only_idx):\n",
        "        forest_MAT[cnt][idx+shift] = 1\n",
        "\n",
        "      n_leaves = len(leaves_order)\n",
        "      shift += n_leaves \n",
        "        \n",
        "    return forest_MAT\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f9PmeP82Ynk"
      },
      "source": [
        "\n",
        "\n",
        "*   Podaci: usps\n",
        "*   Tip: klasifikacija \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlSuN4-BnThl"
      },
      "source": [
        "import h5py\n",
        "\n",
        "\n",
        "\n",
        "#USPS data importing\n",
        "path = \"sample_data/usps.h5\"\n",
        "with h5py.File(path, 'r') as hf:\n",
        "        train_usps = hf.get('train')\n",
        "        X_tr_usps = train_usps.get('data')[:]\n",
        "        y_tr_usps = train_usps.get('target')[:]\n",
        "        test_usps = hf.get('test')\n",
        "        X_te_usps = test_usps.get('data')[:]\n",
        "        y_te_usps = test_usps.get('target')[:]\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def prune_A(mdl,x_train,y_train,x_test,y_test,err_func):\n",
        "    \n",
        "    new_err = float(\"inf\")\n",
        "    max_iter = 5\n",
        "\n",
        "\n",
        "    old_mdl = deepcopy(mdl)\n",
        "    new_mdl = deepcopy(mdl)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "\n",
        "      old_err = new_err\n",
        "      old_mdl = deepcopy(new_mdl)  \n",
        "\n",
        "      new_mdl.pruning_iter(x_train,y_train)\n",
        "      y_test_mdl = new_mdl.predict(x_test)\n",
        "      new_err = err_func(y_test_mdl,y_test)\n",
        "\n",
        "      if new_err>=old_err:\n",
        "        break\n",
        "      \n",
        "    return old_err,old_mdl\n",
        "\n",
        "def prune_E(mdl,x_train,y_train,x_test,y_test,err_func,acc):\n",
        "  old_err = -1\n",
        "  new_err = -1\n",
        "  old_mdl = deepcopy(mdl)\n",
        "  new_mdl = deepcopy(mdl)\n",
        "  iter = 0\n",
        "  while(acc > new_err):\n",
        "    old_err = new_err\n",
        "    old_mdl = deepcopy(new_mdl)\n",
        "\n",
        "    new_mdl.pruning_iter(x_train,y_train)\n",
        "    y_test_mdl = new_mdl.predict(x_test)\n",
        "    new_err = err_func(y_test_mdl,y_test)\n",
        "\n",
        "    if(iter==8):\n",
        "      break\n",
        "    iter +=1\n",
        "  if old_err == -1:\n",
        "    return err_func(old_mdl.predict(x_test),y_test),old_mdl\n",
        "  return old_err,old_mdl\n",
        "\n",
        "def comp_Acc(y_te,y_pred):\n",
        "  return 1-accuracy_score(y_te,y_pred)"
      ],
      "metadata": {
        "id": "ygzXXLFSQb0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IphrJmyvKSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8f2b37-8fe4-4a59-a9bd-570564f651e4"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mdl_rfc = RandomForestClassifier(max_depth = 15, n_estimators = 100,min_samples_split = 5,max_features = \"sqrt\")\n",
        "mdl_rfc.fit(X_tr_usps,y_tr_usps)\n",
        "y_pred_usps = mdl_rfc.predict(X_te_usps)\n",
        "\n",
        "mdl_svc = LinearSVC()\n",
        "\n",
        "cm_model = CustomModel(mdl_rfc,mdl_svc)\n",
        "\n",
        "cm_model.train(X_tr_usps,y_tr_usps)\n",
        "\n",
        "\n",
        "errA,mdlA = prune_A(cm_model,X_tr_usps,y_tr_usps,X_te_usps,y_te_usps,comp_Acc)\n",
        "#errE,mdlE = prune_E(cm_model,X_tr_usps,y_tr_usps,X_te_usps,y_te_usps,comp_Acc,comp_Acc(y_pred_usps,y_te_usps))\n",
        "\n",
        "print(\"err REF_A: \",errA)\n",
        "#print(\"err REF_E: \",errE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "err REF_A:  0.05430991529646234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Podaci: letter\n",
        "*   Tip: klasifikacija "
      ],
      "metadata": {
        "id": "imcj4qMT9q0f"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fweLdNjAwO5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "ecb53ec0-5ff2-4648-ff33-6e3a2f677d17"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "path = \"sample_data/letter-recognition.data\"\n",
        "with open(path, 'r') as lr:\n",
        "  lines = lr.read().split(\"\\n\")\n",
        "  X_let = list()\n",
        "  y_let = list()\n",
        "  for line in lines:\n",
        "    splited_line = line.split(\",\")\n",
        "    y_let.append(splited_line[0])\n",
        "    X_let.append(splited_line[1:])\n",
        "  y_let.pop()\n",
        "  X_let.pop()\n",
        "  y_let = np.array(y_let)\n",
        "  X_let = np.array(X_let)\n",
        "  X_tr_let,X_te_let,y_tr_let,y_te_let = train_test_split(X_let,y_let,test_size = 0.4)\n",
        "  \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3ca2f0a8a467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sample_data/letter-recognition.data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX_let\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/letter-recognition.data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mdl_rfc = RandomForestClassifier(max_depth = 15, n_estimators = 100,min_samples_split = 5,max_features = \"sqrt\")\n",
        "mdl_rfc.fit(X_tr_let,y_tr_let)\n",
        "y_pred_let = mdl_rfc.predict(X_te_let)\n",
        "\n",
        "mdl_svc = LinearSVC()\n",
        "\n",
        "cm_model = CustomModel(mdl_rfc,mdl_svc)\n",
        "\n",
        "cm_model.train(X_tr_let,y_tr_let)\n",
        "\n",
        "\n",
        "errA,mdlA = prune_A(cm_model,X_tr_let,y_tr_let,X_te_let,y_te_let,comp_Acc)\n",
        "errE,mdlE = prune_E(cm_model,X_tr_let,y_tr_let,X_te_let,y_te_let,comp_Acc,comp_Acc(y_pred_let,y_te_let))\n",
        "\n",
        "print(\"err REF_A: \",errA)\n",
        "print(\"err REF_E: \",errE)"
      ],
      "metadata": {
        "id": "ustvs7p398wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Podaci: abalone\n",
        "*   Tip: regresija "
      ],
      "metadata": {
        "id": "UvFFPXn59-Zp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGEzQcTqEYCq"
      },
      "source": [
        "path = \"sample_data/abalone.data\"\n",
        "with open(path, 'r') as lr:\n",
        "  lines = lr.read().split(\"\\n\")\n",
        "  X_aba = list()\n",
        "  y_aba = list()\n",
        "  for line in lines:\n",
        "    splited_line = line.split(\",\")\n",
        "    y_aba.append(splited_line[-1])\n",
        "    X_aba.append(splited_line[1:-1])\n",
        "  y_aba.pop()\n",
        "  X_aba.pop()\n",
        "  y_aba = np.array(y_aba)\n",
        "  X_aba = np.array(X_aba)\n",
        "  X_tr_aba,X_te_aba,y_tr_aba,y_te_aba = train_test_split(X_aba,y_aba,test_size = 0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def rmse(y_real,y_pred):\n",
        "  return mean_squared_error(y_real,y_pred,squared=False)\n",
        "\n",
        "mdl_rfr = RandomForestRegressor(max_depth = 10, n_estimators = 100,min_samples_split = 5,max_features = \"sqrt\")\n",
        "mdl_rfr.fit(X_tr_aba,y_tr_aba)\n",
        "y_pred_aba = mdl_rfr.predict(X_te_aba)\n",
        "\n",
        "mdl_rid = Ridge()\n",
        "\n",
        "\n",
        "cm_model = CustomModel(mdl_rfr,mdl_rid,True)\n",
        "\n",
        "cm_model.train(X_tr_aba,y_tr_aba)\n",
        "\n",
        "errA,mdlA = prune_A(cm_model,X_tr_aba,y_tr_aba,X_te_aba,y_te_aba,rmse)\n",
        "errE,mdlE = prune_E(cm_model,X_tr_aba,y_tr_aba,X_te_aba,y_te_aba,rmse,rmse(y_pred_aba,y_te_aba))\n",
        "\n",
        "\n",
        "print(\"err REF_A: \",errA)\n",
        "print(\"err REF_E: \",errE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FwunotKCQAnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ad4155-b415-48f8-e1a5-266830333c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "err REF_A:  2.423515964230933\n",
            "err REF_E:  2.423680430087986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:91: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Podaci: ailerons\n",
        "*   Tip: regresija "
      ],
      "metadata": {
        "id": "dnsdZU_R4G6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"sample_data/ailerons.csv\"\n",
        "with open(path, 'r') as lr:\n",
        "  lines = lr.read().split(\"\\n\")\n",
        "  X_ail = list()\n",
        "  y_ail = list()\n",
        "  it = True\n",
        "  for line in lines:\n",
        "    if it:\n",
        "      it = False\n",
        "      continue\n",
        "    splited_line = line.split(\",\")\n",
        "    y_ail.append(splited_line[-1])\n",
        "    X_ail.append(splited_line[1:-1])\n",
        "  y_ail.pop()\n",
        "  X_ail.pop()\n",
        "  y_ail = np.array(y_ail)\n",
        "  X_ail = np.array(X_ail)\n",
        "  X_tr_ail,X_te_ail,y_tr_ail,y_te_ail = train_test_split(X_ail,y_ail,test_size = 0.4)"
      ],
      "metadata": {
        "id": "-ID6v_p37NQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mdl_rfr = RandomForestRegressor(max_depth = 10, n_estimators = 100,min_samples_split = 5,max_features = \"sqrt\")\n",
        "mdl_rid = Ridge()\n",
        "mdl_rfr.fit(X_tr_ail,y_tr_ail)\n",
        "y_pred_ail = mdl_rfr.predict(X_te_ail)\n",
        "\n",
        "cm_model = CustomModel(mdl_rfr,mdl_rid,True)\n",
        "\n",
        "cm_model.train(X_tr_ail,y_tr_ail)\n",
        "\n",
        "errA,mdlA = prune_A(cm_model,X_tr_ail,y_tr_ail,X_te_ail,y_te_ail,rmse)\n",
        "errE,mdlE = prune_E(cm_model,X_tr_ail,y_tr_ail,X_te_ail,y_te_ail,rmse,rmse(y_pred_ail,y_te_ail))\n",
        "\n",
        "print(\"err REF_A: \",errA)\n",
        "print(\"err REF_E: \",errE)"
      ],
      "metadata": {
        "id": "8mprEsqm8cJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "09bf7179-362f-4226-99b1-d696ecf63f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-73160eee4d42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl_rfr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmdl_rid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_ail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr_ail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0merrA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmdlA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_tr_ail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr_ail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_te_ail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_te_ail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-abcb6a8bed83>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetTreesCont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mX_svc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchIndVectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_svc_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-abcb6a8bed83>\u001b[0m in \u001b[0;36mfetchIndVectors\u001b[0;34m(self, x_train)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0mleaf_glob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mleaves_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees_cont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mleaf_only_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mleaf_glob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-abcb6a8bed83>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0mleaf_glob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mleaves_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees_cont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mleaf_only_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mleaf_glob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}